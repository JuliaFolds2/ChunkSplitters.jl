var documenterSearchIndex = {"docs":
[{"location":"#ChunkSplitters.jl","page":"Home","title":"ChunkSplitters.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ChunkSplitters.jl facilitates the splitting of a given list of work items (of potentially uneven workload) into chunks that can be readily used for parallel processing. Operations on these chunks can, for example, be parallelized with Julia's multithreading tools, where separate tasks are created for each chunk. Compared to naive parallelization, ChunkSplitters.jl therefore effectively allows for more fine-grained control of the composition and workload of each parallel task.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Working with chunks and their respective indices also improves thread-safety compared to a naive approach based on threadid() indexing (see PSA: Thread-local state is no longer recommended). ","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Install with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> import Pkg; Pkg.add(\"ChunkSplitters\")","category":"page"},{"location":"#The-chunks-iterator","page":"Home","title":"The chunks iterator","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The main interface is the chunks iterator:","category":"page"},{"location":"","page":"Home","title":"Home","text":"chunks(array::AbstractArray, nchunks::Int, type::Symbol=:batch)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This iterator returns a Tuple{UnitRange,Int} which indicates the range of indices of the input array for each given chunk and the index of the latter. The type parameter is optional. If type == :batch, the ranges are consecutive (default behavior). If type == :scatter, the range is scattered over the array.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The different chunking variants are illustrated in the following figure: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: splitter types)","category":"page"},{"location":"","page":"Home","title":"Home","text":"For type=:batch, each chunk is \"filled up\" one after another with work items such that all chunks hold the same number of work items (as far as possible). For type=:scatter, the work items are assigned to chunks in a round-robin fashion. As shown below, this way of chunking can be beneficial if the workload (i.e. the computational weight) for different items is uneven. ","category":"page"},{"location":"#Basic-example","page":"Home","title":"Basic example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Let's first illustrate the chunks returned by chunks for the different chunking variants:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using ChunkSplitters \n\njulia> x = rand(7);\n\njulia> for (xrange,ichunk) in chunks(x, 3, :batch)\n           @show (xrange, ichunk)\n       end\n(xrange, ichunk) = (1:3, 1)\n(xrange, ichunk) = (4:5, 2)\n(xrange, ichunk) = (6:7, 3)\n\njulia> for (xrange,ichunk) in chunks(x, 3, :scatter)\n           @show (xrange, ichunk)\n       end\n(xrange, ichunk) = (1:3:7, 1)\n(xrange, ichunk) = (2:3:5, 2)\n(xrange, ichunk) = (3:3:6, 3)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Now, let's demonstrate how to use chunks in a simple multi-threaded example:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using BenchmarkTools\n\njulia> using ChunkSplitters\n\njulia> function sum_parallel(f, x; nchunks=Threads.nthreads())\n           s = fill(zero(eltype(x)), nchunks)\n           Threads.@threads for (xrange, ichunk) in chunks(x, nchunks)\n               for i in xrange\n                  s[ichunk] += f(x[i])\n               end\n           end\n           return sum(s)\n       end\n\njulia> x = rand(10^7);\n\njulia> Threads.nthreads()\n12\n\njulia> @btime sum(x -> log(x)^7, $x)\n  115.026 ms (0 allocations: 0 bytes)\n-5.062317099586189e10\n\njulia> @btime sum_parallel(x -> log(x)^7, $x; nchunks=Threads.nthreads())\n  33.723 ms (77 allocations: 6.55 KiB)\n-5.062317099581316e10","category":"page"},{"location":"","page":"Home","title":"Home","text":"Apart from @threads, chunks can of course also be used in conjuction with @spawn. See below for an explicit example.","category":"page"},{"location":"","page":"Home","title":"Home","text":"note: Note\nNote that increasing the number of chunks beyond nthreads() gives better performance for the simple parallel-sum implementation shown above. However, this is due to more subtle effects (false-sharing) and not related to the chunking and the distribution of work among threads. For well-designed parallel algorithms, nchunks == nthreads() should be optimal in conjuction with @threads.","category":"page"},{"location":"#Load-balancing-considerations","page":"Home","title":"Load balancing considerations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We create a very unbalanced workload:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> work_load = collect(div(10^4,i) for i in 1:64);\n\njulia> using UnicodePlots\n\njulia> lineplot(work_load; xlabel=\"task\", ylabel=\"workload\")\n                   ┌────────────────────────────────────────┐ \n            10 000 │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠸⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n   workload        │⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⢱⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⠸⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⠀⢇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⠀⠈⢆⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⠀⠀⠀⠈⠲⢤⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                 0 │⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠉⠓⠒⠒⠒⠒⠒⠦⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⣀⣀⣀⠀⠀⠀│ \n                   └────────────────────────────────────────┘ \n                   ⠀0⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀70⠀ \n                   ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀task⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The scenario that we will consider below is the following: We want to parallize the operation \"sum log(x[i])^7 for x[i]\", where x is a regular array. However, to establish the uneven workload shown above, we will make each task sum up a different number of elements of x, specifically as many elements as is indicated by the work_load array for the given task/work item.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For parallelization, we will use Threads.@threads and Threads.@sync/Threads.@spawn, which imply different possibilities of load balancing, in conjuction with the different chunking variants :batch and :scatter.","category":"page"},{"location":"#Using-@threads","page":"Home","title":"Using @threads","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"First, we consider a variant where the @threads macro is used. The multithreaded operation is:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using Base.Threads, ChunkSplitters\n\njulia> function uneven_workload_threads(x, work_load; nchunks::Int, chunk_type::Symbol)\n           s = fill(zero(eltype(x)), nchunks)\n           @threads for (xrange, ichunk) in chunks(work_load, nchunks, chunk_type)\n               for i in xrange\n                   s[ichunk] += sum(log(x[j])^7 for j in 1:work_load[i]) \n               end\n           end\n           return sum(s)\n       end","category":"page"},{"location":"","page":"Home","title":"Home","text":"Using nchunks == Thread.nthreads() == 8, we get the following timings:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using BenchmarkTools \n\njulia> @btime uneven_workload_threads($x, $work_load; nchunks=Thread.nthreads(), chunk_type=:batch)\n  1.451 ms (46 allocations: 4.61 KiB)\n-1.5503788131612685e8\n\njulia> @btime uneven_workload_threads($x, $work_load; nchunks=Thread.nthreads(), chunk_type=:scatter)\n  826.857 μs (46 allocations: 4.61 KiB)\n-1.5503788131612682e8","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that despite the fact that @threads doesn't balance load internally, one can get \"poor man's load balancing\", and thus better performance for the given uneven workload, by using :scatter instead of :batch. This is because for :scatter we create chunks by sampling from the entire workload such that chunks will consist of work items with vastly different computational weight. In contrast, for :batch, the first couple of chunks will have very high workload whereas the latter ones are computationally cheap.","category":"page"},{"location":"#Using-@sync/@spawn","page":"Home","title":"Using @sync/@spawn","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In contrast to @threads, @spawn implements load balancing through Julia's task scheduler. Specifically, the spawned tasks, corresponding to chunks from our work_load array, are taken as they are and will be dynamically scheduled at runtime. (Compare this to @threads which will create a task for multiple of our chunks, thus, effectively, performing its own internal \"chunking\".)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The implementation is similar to above but this time based on @spawn (and @sync):","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> function uneven_workload_spawn(x, work_load; nchunks::Int, chunk_type::Symbol)\n           s = fill(zero(eltype(x)), nchunks)\n           @sync for (xrange, ichunk) in chunks(work_load, nchunks, chunk_type)\n               @spawn for i in xrange\n                   s[ichunk] += sum(log(x[j])^7 for j in 1:work_load[i]) \n               end\n           end\n           return sum(s)\n       end","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that for nchunks == Thread.nthreads() == 8 we observer similar (only slightly better) timings as for the @threads example above","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> @btime uneven_workload_spawn($x, $work_load; nchunks=Thread.nthreads(), chunk_type=:batch)\n  1.398 ms (59 allocations: 5.08 KiB)\n-1.5503788131612685e8\n\njulia> @btime uneven_workload_spawn($x, $work_load; nchunks=Thread.nthreads(), chunk_type=:scatter)\n  745.953 μs (59 allocations: 5.08 KiB)\n-1.5503788131612682e8","category":"page"},{"location":"","page":"Home","title":"Home","text":"This isn't surprising because by choosing nchunks == Thread.nthreads() we're closely mimicing the \"chunking\" that @threads is doing internally and leaving not much freedom to the load balancer (because each thread gets a single chunk/task anyways).","category":"page"},{"location":"","page":"Home","title":"Home","text":"However, by choosing a larger value for nchunks we can improve the load balancing, and thus the performance, by giving the Julia's dynamic scheduler more tasks (\"units of work\") to balance out:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> @btime uneven_workload_spawn($x, $work_load; nchunks=64, chunk_type=:batch)\n  603.476 μs (398 allocations: 38.83 KiB)\n-1.5503788131612682e8","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that the same does not work when using @threads, because the first 8 chunks will noneless be assigned to the same thread (because of the automatic interal \"chunking\"):","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> @btime uneven_workload_threads($x, $work_load; nchunks=64, chunk_type=:batch)\n  1.451 ms (47 allocations: 5.08 KiB)\n-1.5503788131612682e8","category":"page"},{"location":"#Lower-level-getchunk-function","page":"Home","title":"Lower-level getchunk function","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package also provides a lower-level getchunk function:","category":"page"},{"location":"","page":"Home","title":"Home","text":"getchunk(array::AbstractArray, ichunk::Int, nchunks::Int, type::Symbol=:batch)","category":"page"},{"location":"","page":"Home","title":"Home","text":"that returns the range of indexes corresponding to the work items in the input array that are associated with chunk number ichunk. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"note: Note\nThe getchunk function is available in version 2 of the package. In version 1 it was named chunks. ","category":"page"},{"location":"#Example:-chunking-variants","page":"Home","title":"Example: chunking variants","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For example, if we have an array of 7 elements, and the work on the elements is divided into 3 chunks, we have (using the default type = :batch option):","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using ChunkSplitters\n\njulia> x = rand(7);\n\njulia> getchunk(x, 1, 3)\n1:3\n\njulia> getchunk(x, 2, 3)\n4:5\n\njulia> getchunk(x, 3, 3)\n6:7","category":"page"},{"location":"","page":"Home","title":"Home","text":"And using type = :scatter, we have:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> getchunk(x, 1, 3, :scatter)\n1:3:7\n\njulia> getchunk(x, 2, 3, :scatter)\n2:3:5\n\njulia> getchunk(x, 3, 3, :scatter)\n3:3:6","category":"page"},{"location":"#Example","page":"Home","title":"Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"julia> using BenchmarkTools\n\njulia> using ChunkSplitters\n\njulia> function sum_parallel(f, x; nchunks=Threads.nthreads())\n           s = fill(zero(eltype(x)), nchunks)\n           Threads.@threads for ichunk in 1:nchunks\n               for i in getchunk(x, ichunk, nchunks)\n                   s[ichunk] += f(x[i])\n               end\n           end\n           return sum(s)\n       end\n\njulia> x = rand(10^7);\n\njulia> Threads.nthreads()\n6\n\njulia> @btime sum(x -> log(x)^7, $x)\n  238.039 ms (0 allocations: 0 bytes)\n-5.062317099586189e10\n\njulia> @btime sum_parallel(x -> log(x)^7, $x; nchunks=Threads.nthreads())\n  81.112 ms (38 allocations: 3.27 KiB)\n-5.062317099581316e10","category":"page"}]
}
