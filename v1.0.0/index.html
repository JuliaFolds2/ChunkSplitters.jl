<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · ChunkSplitters.jl</title><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.svg" alt="ChunkSplitters.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href>ChunkSplitters.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#The-chunks-iterator"><span>The <code>chunks</code> iterator</span></a></li><li><a class="tocitem" href="#Examples"><span>Examples</span></a></li><li><a class="tocitem" href="#Lower-level-chunks-function"><span>Lower-level chunks function</span></a></li><li><a class="tocitem" href="#Load-balancing-considerations"><span>Load balancing considerations</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/m3g/ChunkSplitters.jl/blob/main/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="ChunkSplitters.jl"><a class="docs-heading-anchor" href="#ChunkSplitters.jl">ChunkSplitters.jl</a><a id="ChunkSplitters.jl-1"></a><a class="docs-heading-anchor-permalink" href="#ChunkSplitters.jl" title="Permalink"></a></h1><p><a href="https://github.com/m3g/ChunkSplitters.jl">ChunkSplitters.jl</a> facilitate the splitting of the workload of parallel jobs independently on the number of threads that are effectively available. It allows for a finer, lower level, control of the load of each task.</p><p>The way chunks are indexed is also recommended for guaranteeing that the workload if completely thread safe  (without the use <code>threadid()</code> - see <a href="https://juliafolds.github.io/FLoops.jl/dev/explanation/faq/#faq-state-threadid">here</a>). </p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><p>Install with:</p><pre><code class="language-julia-repl hljs">julia&gt; import Pkg; Pkg.add(&quot;ChunkSplitters&quot;)</code></pre><h2 id="The-chunks-iterator"><a class="docs-heading-anchor" href="#The-chunks-iterator">The <code>chunks</code> iterator</a><a id="The-chunks-iterator-1"></a><a class="docs-heading-anchor-permalink" href="#The-chunks-iterator" title="Permalink"></a></h2><p>The main interface is the <code>chunks</code> iterator:</p><pre><code class="language-julia hljs">chunks(array::AbstractArray, nchunks::Int, type::Symbol=:batch)</code></pre><p>This iterator returns a <code>Tuple{UnitRange,Int}</code> with the range of indices of <code>array</code> to be iterated for each given chunk. If <code>type == :batch</code>, the ranges are consecutive. If <code>type == :scatter</code>, the range is scattered over the array. </p><p>The chunking types are illustrated in the figure below: </p><p><img src="assets/splitters.svg" alt="splitter types"/></p><p>In the <code>:batch</code> type, the tasks are associated to each thread until the fraction of the workload of that thread is  complete. In the <code>:scatter</code> type, the tasks are assigned in an alternating fashion. If the workload is uneven and correlated with its position in the input array, the <code>:scatter</code> option will be more efficient. </p><h2 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h2><p>Here we illustrate which are the indexes of the chunks returned by each iterator:</p><pre><code class="language-julia hljs">julia&gt; using ChunkSplitters 

julia&gt; x = rand(7);

julia&gt; Threads.@threads for (xrange,ichunk) in chunks(x, 3, :batch)
           @show (xrange, ichunk)
       end
(xrange, ichunk) = (1:3, 1)
(xrange, ichunk) = (6:7, 3)
(xrange, ichunk) = (4:5, 2)

julia&gt; Threads.@threads for (xrange,ichunk) in chunks(x, 3, :scatter)
           @show (xrange, ichunk)
       end
(xrange, ichunk) = (2:3:5, 2)
(xrange, ichunk) = (1:3:7, 1)
(xrange, ichunk) = (3:3:6, 3)</code></pre><p>If the third argument is ommitted (i. e. <code>:batch</code> or <code>:scatter</code>), the default <code>:batch</code> option is used.</p><p>Now, we illustrate the use of the iterator in a practical example:</p><pre><code class="language-julia hljs">julia&gt; using BenchmarkTools

julia&gt; using ChunkSplitters

julia&gt; function sum_parallel(f, x; nchunks=Threads.nthreads())
           s = fill(zero(eltype(x)), nchunks)
           Threads.@threads for (xrange, ichunk) in chunks(x, nchunks)
               for i in xrange
                  s[ichunk] += f(x[i])
               end
           end
           return sum(s)
       end

julia&gt; x = rand(10^7);

julia&gt; Threads.nthreads()
12

julia&gt; @btime sum(x -&gt; log(x)^7, $x)
  115.026 ms (0 allocations: 0 bytes)
-5.062317099586189e10

julia&gt; @btime sum_parallel(x -&gt; log(x)^7, $x; nchunks=12)
  33.723 ms (77 allocations: 6.55 KiB)
-5.062317099581316e10</code></pre><h2 id="Lower-level-chunks-function"><a class="docs-heading-anchor" href="#Lower-level-chunks-function">Lower-level chunks function</a><a id="Lower-level-chunks-function-1"></a><a class="docs-heading-anchor-permalink" href="#Lower-level-chunks-function" title="Permalink"></a></h2><p>The package also provides a lower-level chunks function:</p><pre><code class="language-julia hljs">chunks(array::AbstractArray, ichunk::Int, nchunks::Int, type::Symbol=:batch)</code></pre><p>that returns a range of indexes of <code>array</code>, given the number of chunks in which the array is to be split, <code>nchunks</code>, and the current chunk number <code>ichunk</code>. </p><h3 id="Example"><a class="docs-heading-anchor" href="#Example">Example</a><a id="Example-1"></a><a class="docs-heading-anchor-permalink" href="#Example" title="Permalink"></a></h3><p>The example shows how to compute a sum of a function applied to the elements of an array, and the effect of the parallelization and the number of chunks in the performance:</p><pre><code class="language-julia hljs">julia&gt; using BenchmarkTools

julia&gt; using ChunkSplitters: chunks

julia&gt; function sum_parallel(f, x; nchunks=Threads.nthreads())
           s = fill(zero(eltype(x)), nchunks)
           Threads.@threads for ichunk in 1:nchunks
               for i in chunks(x, ichunk, nchunks)
                   s[ichunk] += f(x[i])
               end
           end
           return sum(s)
       end

julia&gt; x = rand(10^7);

julia&gt; Threads.nthreads()
12

julia&gt; @btime sum(x -&gt; log(x)^7, $x)
  122.085 ms (0 allocations: 0 bytes)
-5.062317099586189e10

julia&gt; @btime sum_parallel(x -&gt; log(x)^7, $x; nchunks=4)
  34.802 ms (74 allocations: 6.61 KiB)
-5.062317099581316e10</code></pre><h3 id="Examples-of-different-splitters"><a class="docs-heading-anchor" href="#Examples-of-different-splitters">Examples of different splitters</a><a id="Examples-of-different-splitters-1"></a><a class="docs-heading-anchor-permalink" href="#Examples-of-different-splitters" title="Permalink"></a></h3><p>For example, if we have an array of 7 elements, and the work on the elements is divided into 3 chunks, we have (using the default <code>type = :batch</code> option):</p><pre><code class="language-julia hljs">julia&gt; using ChunkSplitters

julia&gt; x = rand(7);

julia&gt; chunks(x, 1, 3)
1:3

julia&gt; chunks(x, 2, 3)
4:5

julia&gt; chunks(x, 3, 3)
6:7</code></pre><p>And using <code>type = :scatter</code>, we have:</p><pre><code class="language-julia hljs">julia&gt; chunks(x, 1, 3, :scatter)
1:3:7

julia&gt; chunks(x, 2, 3, :scatter)
2:3:5

julia&gt; chunks(x, 3, 3, :scatter)
3:3:6</code></pre><h2 id="Load-balancing-considerations"><a class="docs-heading-anchor" href="#Load-balancing-considerations">Load balancing considerations</a><a id="Load-balancing-considerations-1"></a><a class="docs-heading-anchor-permalink" href="#Load-balancing-considerations" title="Permalink"></a></h2><p>Here we define two functions which (artificially) result in very uneven workload distributions among tasks. Basically, we sum <code>log(x[i])^7</code> for <code>x[i]</code> being the elements of an array. However, each task has to sum a different number of elements, defined in a <code>workload</code> vector. The  workload vector will have <code>64</code> tasks, with a workload that decreases for each task. </p><p>The functions are defined using <code>Threads.@threads</code> or <code>Threads.@sync/Threads.@spawn</code> macros of  base julia, which imply different possibilities of load balancing.</p><p>We create a very unbalanced workload, with:</p><pre><code class="language-julia-repl hljs">julia&gt; x = rand(10^4); work_load = collect(div(10^4,i) for i in 1:64);

julia&gt; using UnicodePlots

julia&gt; lineplot(work_load; xlabel=&quot;task&quot;, ylabel=&quot;workload&quot;)
                   ┌────────────────────────────────────────┐ 
            10 000 │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                   │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                   │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                   │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                   │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                   │⠸⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                   │⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
   workload        │⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                   │⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                   │⠀⢱⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                   │⠀⠸⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                   │⠀⠀⢇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                   │⠀⠀⠈⢆⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                   │⠀⠀⠀⠀⠈⠲⢤⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                 0 │⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠉⠓⠒⠒⠒⠒⠒⠦⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⣀⣀⣀⠀⠀⠀│ 
                   └────────────────────────────────────────┘ 
                   ⠀0⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀70⠀ 
                   ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀task⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ </code></pre><p>Thus, the first tasks will operate on all elements of the array, while the final tasks will perform a sum over much less elements. </p><h3 id="Using-@threads"><a class="docs-heading-anchor" href="#Using-@threads">Using <code>@threads</code></a><a id="Using-@threads-1"></a><a class="docs-heading-anchor-permalink" href="#Using-@threads" title="Permalink"></a></h3><p>First, we consider the case where the <code>@threads</code> macro is used. The threaded operation is:</p><pre><code class="language-julia hljs">julia&gt; using Base.Threads, ChunkSplitters

julia&gt; function uneven_workload_threads(x, work_load; nchunks::Int, chunk_type::Symbol)
           s = fill(zero(eltype(x)), nchunks)
           @threads for (xrange, ichunk) in chunks(work_load, nchunks, chunk_type)
               for i in xrange
                   s[ichunk] += sum(log(x[j])^7 for j in 1:work_load[i]) 
               end
           end
           return sum(s)
       end</code></pre><p>Using <code>nchunks == nthreads()</code>, which are <code>8</code> in this case, we get the following timings:</p><pre><code class="language-julia hljs">julia&gt; @btime uneven_workload_threads($x, $work_load; nchunks=8, chunk_type=:batch)
  1.451 ms (46 allocations: 4.61 KiB)
-1.5503788131612685e8

julia&gt; @btime uneven_workload_threads($x, $work_load; nchunks=8, chunk_type=:scatter)
  826.857 μs (46 allocations: 4.61 KiB)
-1.5503788131612682e8</code></pre><p>Therefore, it is possible to deal with the unbalaced workload with the <code>:scatter</code> option, since there is, here, a correlation between chunk index and workload. However, if that is not known, one can deal with the workload by increasing the number of chunks, if using the <code>@sync/@spawn</code> option:</p><h3 id="Using-@sync/@spawn"><a class="docs-heading-anchor" href="#Using-@sync/@spawn">Using <code>@sync/@spawn</code></a><a id="Using-@sync/@spawn-1"></a><a class="docs-heading-anchor-permalink" href="#Using-@sync/@spawn" title="Permalink"></a></h3><p>The same pattern can be used if the <code>@sync/@spawn</code> macros where used for spawning threads. The difference is that the spawned tasks are not bound to any thread, such that varying the number of chunks can have an effect on the load balancing. </p><p>The function is similar to the previous one,</p><pre><code class="language-julia hljs">julia&gt; function uneven_workload_spawn(x, work_load; nchunks::Int, chunk_type::Symbol)
           s = fill(zero(eltype(x)), nchunks)
           @sync for (xrange, ichunk) in chunks(work_load, nchunks, chunk_type)
               @spawn for i in xrange
                   s[ichunk] += sum(log(x[j])^7 for j in 1:work_load[i]) 
               end
           end
           return sum(s)
       end</code></pre><p>And we get a similar speedup when using the <code>:scatter</code> chunking style:</p><pre><code class="language-julia hljs">julia&gt; @btime uneven_workload_spawn($x, $work_load; nchunks=8, chunk_type=:batch)
  1.398 ms (59 allocations: 5.08 KiB)
-1.5503788131612685e8

julia&gt; @btime uneven_workload_spawn($x, $work_load; nchunks=8, chunk_type=:scatter)
  745.953 μs (59 allocations: 5.08 KiB)
-1.5503788131612682e8</code></pre><p>Now, alternativelly (or additionally), one can vary the number of chunks, and that can improve the load balancing as well:</p><pre><code class="language-julia hljs">julia&gt; @btime uneven_workload_spawn($x, $work_load; nchunks=64, chunk_type=:batch)
  603.476 μs (398 allocations: 38.83 KiB)
-1.5503788131612682e8</code></pre><p>Note that the same does not work if using <code>@threads</code>, because the first <code>8</code> tasks will noneless be assigned to the same thread:</p><pre><code class="language-julia hljs">julia&gt; @btime uneven_workload_threads($x, $work_load; nchunks=64, chunk_type=:batch)
  1.451 ms (47 allocations: 5.08 KiB)
-1.5503788131612682e8</code></pre></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.22 on <span class="colophon-date" title="Tuesday 1 August 2023 17:47">Tuesday 1 August 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
