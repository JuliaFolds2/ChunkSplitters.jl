var documenterSearchIndex = {"docs":
[{"location":"#ChunkSplitters.jl","page":"Home","title":"ChunkSplitters.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ChunkSplitters.jl facilitate the splitting of the workload of parallel jobs independently on the number of threads that are effectively available. It allows for a finer, lower level, control of the load of each task.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The way chunks are indexed is also recommended for guaranteeing that the workload if completely thread safe  (without the use threadid() - see here). ","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Install with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> import Pkg; Pkg.add(\"ChunkSplitters\")","category":"page"},{"location":"#The-chunks-iterator","page":"Home","title":"The chunks iterator","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The main interface is the chunks iterator:","category":"page"},{"location":"","page":"Home","title":"Home","text":"chunks(array::AbstractArray, nchunks::Int, type::Symbol=:batch)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This iterator returns a Tuple{UnitRange,Int} with the range of indices of array to be iterated for each given chunk. If type == :batch, the ranges are consecutive. If type == :scatter, the range is scattered over the array. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The chunking types are illustrated in the figure below: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: splitter types)","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the :batch type, the tasks are associated to each thread until the fraction of the workload of that thread is  complete. In the :scatter type, the tasks are assigned in an alternating fashion. If the workload is uneven and correlated with its position in the input array, the :scatter option will be more efficient. ","category":"page"},{"location":"#Examples","page":"Home","title":"Examples","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Here we illustrate which are the indexes of the chunks returned by each iterator:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using ChunkSplitters \n\njulia> x = rand(7);\n\njulia> Threads.@threads for (xrange,ichunk) in chunks(x, 3, :batch)\n           @show (xrange, ichunk)\n       end\n(xrange, ichunk) = (1:3, 1)\n(xrange, ichunk) = (6:7, 3)\n(xrange, ichunk) = (4:5, 2)\n\njulia> Threads.@threads for (xrange,ichunk) in chunks(x, 3, :scatter)\n           @show (xrange, ichunk)\n       end\n(xrange, ichunk) = (2:3:5, 2)\n(xrange, ichunk) = (1:3:7, 1)\n(xrange, ichunk) = (3:3:6, 3)","category":"page"},{"location":"","page":"Home","title":"Home","text":"If the third argument is ommitted (i. e. :batch or :scatter), the default :batch option is used.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Now, we illustrate the use of the iterator in a practical example:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using BenchmarkTools\n\njulia> using ChunkSplitters\n\njulia> function sum_parallel(f, x; nchunks=Threads.nthreads())\n           s = fill(zero(eltype(x)), nchunks)\n           Threads.@threads for (xrange, ichunk) in chunks(x, nchunks)\n               for i in xrange\n                  s[ichunk] += f(x[i])\n               end\n           end\n           return sum(s)\n       end\n\njulia> x = rand(10^7);\n\njulia> Threads.nthreads()\n12\n\njulia> @btime sum(x -> log(x)^7, $x)\n  115.026 ms (0 allocations: 0 bytes)\n-5.062317099586189e10\n\njulia> @btime sum_parallel(x -> log(x)^7, $x; nchunks=12)\n  33.723 ms (77 allocations: 6.55 KiB)\n-5.062317099581316e10","category":"page"},{"location":"#Lower-level-chunks-function","page":"Home","title":"Lower-level chunks function","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package also provides a lower-level chunks function:","category":"page"},{"location":"","page":"Home","title":"Home","text":"chunks(array::AbstractArray, ichunk::Int, nchunks::Int, type::Symbol=:batch)","category":"page"},{"location":"","page":"Home","title":"Home","text":"that returns a range of indexes of array, given the number of chunks in which the array is to be split, nchunks, and the current chunk number ichunk. ","category":"page"},{"location":"#Example","page":"Home","title":"Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The example shows how to compute a sum of a function applied to the elements of an array, and the effect of the parallelization and the number of chunks in the performance:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using BenchmarkTools\n\njulia> using ChunkSplitters: chunks\n\njulia> function sum_parallel(f, x; nchunks=Threads.nthreads())\n           s = fill(zero(eltype(x)), nchunks)\n           Threads.@threads for ichunk in 1:nchunks\n               for i in chunks(x, ichunk, nchunks)\n                   s[ichunk] += f(x[i])\n               end\n           end\n           return sum(s)\n       end\n\njulia> x = rand(10^7);\n\njulia> Threads.nthreads()\n12\n\njulia> @btime sum(x -> log(x)^7, $x)\n  122.085 ms (0 allocations: 0 bytes)\n-5.062317099586189e10\n\njulia> @btime sum_parallel(x -> log(x)^7, $x; nchunks=4)\n  34.802 ms (74 allocations: 6.61 KiB)\n-5.062317099581316e10","category":"page"},{"location":"#Examples-of-different-splitters","page":"Home","title":"Examples of different splitters","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For example, if we have an array of 7 elements, and the work on the elements is divided into 3 chunks, we have (using the default type = :batch option):","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using ChunkSplitters\n\njulia> x = rand(7);\n\njulia> chunks(x, 1, 3)\n1:3\n\njulia> chunks(x, 2, 3)\n4:5\n\njulia> chunks(x, 3, 3)\n6:7","category":"page"},{"location":"","page":"Home","title":"Home","text":"And using type = :scatter, we have:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> chunks(x, 1, 3, :scatter)\n1:3:7\n\njulia> chunks(x, 2, 3, :scatter)\n2:3:5\n\njulia> chunks(x, 3, 3, :scatter)\n3:3:6","category":"page"},{"location":"#Load-balancing-considerations","page":"Home","title":"Load balancing considerations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Here we define two functions which (artificially) result in very uneven workload distributions among tasks. Basically, we sum log(x[i])^7 for x[i] being the elements of an array. However, each task has to sum a different number of elements, defined in a workload vector. The  workload vector will have 64 tasks, with a workload that decreases for each task. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The functions are defined using Threads.@threads or Threads.@sync/Threads.@spawn macros of  base julia, which imply different possibilities of load balancing.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We create a very unbalanced workload, with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> x = rand(10^4); work_load = collect(div(10^4,i) for i in 1:64);\n\njulia> using UnicodePlots\n\njulia> lineplot(work_load; xlabel=\"task\", ylabel=\"workload\")\n                   ┌────────────────────────────────────────┐ \n            10 000 │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠸⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n   workload        │⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⢱⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⠸⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⠀⢇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⠀⠈⢆⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                   │⠀⠀⠀⠀⠈⠲⢤⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ \n                 0 │⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠉⠓⠒⠒⠒⠒⠒⠦⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⣀⣀⣀⠀⠀⠀│ \n                   └────────────────────────────────────────┘ \n                   ⠀0⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀70⠀ \n                   ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀task⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Thus, the first tasks will operate on all elements of the array, while the final tasks will perform a sum over much less elements. ","category":"page"},{"location":"#Using-@threads","page":"Home","title":"Using @threads","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"First, we consider the case where the @threads macro is used. The threaded operation is:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using Base.Threads, ChunkSplitters\n\njulia> function uneven_workload_threads(x, work_load; nchunks::Int, chunk_type::Symbol)\n           s = fill(zero(eltype(x)), nchunks)\n           @threads for (xrange, ichunk) in chunks(work_load, nchunks, chunk_type)\n               for i in xrange\n                   s[ichunk] += sum(log(x[j])^7 for j in 1:work_load[i]) \n               end\n           end\n           return sum(s)\n       end","category":"page"},{"location":"","page":"Home","title":"Home","text":"Using nchunks == nthreads(), which are 8 in this case, we get the following timings:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> @btime uneven_workload_threads($x, $work_load; nchunks=8, chunk_type=:batch)\n  1.451 ms (46 allocations: 4.61 KiB)\n-1.5503788131612685e8\n\njulia> @btime uneven_workload_threads($x, $work_load; nchunks=8, chunk_type=:scatter)\n  826.857 μs (46 allocations: 4.61 KiB)\n-1.5503788131612682e8","category":"page"},{"location":"","page":"Home","title":"Home","text":"Therefore, it is possible to deal with the unbalaced workload with the :scatter option, since there is, here, a correlation between chunk index and workload. However, if that is not known, one can deal with the workload by increasing the number of chunks, if using the @sync/@spawn option:","category":"page"},{"location":"#Using-@sync/@spawn","page":"Home","title":"Using @sync/@spawn","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The same pattern can be used if the @sync/@spawn macros where used for spawning threads. The difference is that the spawned tasks are not bound to any thread, such that varying the number of chunks can have an effect on the load balancing. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The function is similar to the previous one,","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> function uneven_workload_spawn(x, work_load; nchunks::Int, chunk_type::Symbol)\n           s = fill(zero(eltype(x)), nchunks)\n           @sync for (xrange, ichunk) in chunks(work_load, nchunks, chunk_type)\n               @spawn for i in xrange\n                   s[ichunk] += sum(log(x[j])^7 for j in 1:work_load[i]) \n               end\n           end\n           return sum(s)\n       end","category":"page"},{"location":"","page":"Home","title":"Home","text":"And we get a similar speedup when using the :scatter chunking style:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> @btime uneven_workload_spawn($x, $work_load; nchunks=8, chunk_type=:batch)\n  1.398 ms (59 allocations: 5.08 KiB)\n-1.5503788131612685e8\n\njulia> @btime uneven_workload_spawn($x, $work_load; nchunks=8, chunk_type=:scatter)\n  745.953 μs (59 allocations: 5.08 KiB)\n-1.5503788131612682e8","category":"page"},{"location":"","page":"Home","title":"Home","text":"Now, alternativelly (or additionally), one can vary the number of chunks, and that can improve the load balancing as well:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> @btime uneven_workload_spawn($x, $work_load; nchunks=64, chunk_type=:batch)\n  603.476 μs (398 allocations: 38.83 KiB)\n-1.5503788131612682e8","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that the same does not work if using @threads, because the first 8 tasks will noneless be assigned to the same thread:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> @btime uneven_workload_threads($x, $work_load; nchunks=64, chunk_type=:batch)\n  1.451 ms (47 allocations: 5.08 KiB)\n-1.5503788131612682e8","category":"page"}]
}
