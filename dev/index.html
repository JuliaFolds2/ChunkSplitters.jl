<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · ChunkSplitters.jl</title><meta name="title" content="Home · ChunkSplitters.jl"/><meta property="og:title" content="Home · ChunkSplitters.jl"/><meta property="twitter:title" content="Home · ChunkSplitters.jl"/><meta name="description" content="Documentation for ChunkSplitters.jl."/><meta property="og:description" content="Documentation for ChunkSplitters.jl."/><meta property="twitter:description" content="Documentation for ChunkSplitters.jl."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.svg" alt="ChunkSplitters.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href>ChunkSplitters.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#The-chunks-iterator"><span>The <code>chunks</code> iterator</span></a></li><li><a class="tocitem" href="#Basic-example"><span>Basic example</span></a></li><li><a class="tocitem" href="#Load-balancing-considerations"><span>Load balancing considerations</span></a></li><li><a class="tocitem" href="#Lower-level-getchunk-function"><span>Lower-level <code>getchunk</code> function</span></a></li></ul></li><li><a class="tocitem" href="references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/m3g/ChunkSplitters.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/m3g/ChunkSplitters.jl/blob/main/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="ChunkSplitters.jl"><a class="docs-heading-anchor" href="#ChunkSplitters.jl">ChunkSplitters.jl</a><a id="ChunkSplitters.jl-1"></a><a class="docs-heading-anchor-permalink" href="#ChunkSplitters.jl" title="Permalink"></a></h1><p><a href="https://github.com/m3g/ChunkSplitters.jl">ChunkSplitters.jl</a> facilitates the splitting of a given list of work items (of potentially uneven workload) into chunks that can be readily used for parallel processing. Operations on these chunks can, for example, be parallelized with Julia&#39;s multithreading tools, where separate tasks are created for each chunk. Compared to naive parallelization, ChunkSplitters.jl therefore effectively allows for more fine-grained control of the composition and workload of each parallel task.</p><p>Working with chunks and their respective indices also improves thread-safety compared to a naive approach based on <code>threadid()</code> indexing (see <a href="https://julialang.org/blog/2023/07/PSA-dont-use-threadid/">PSA: Thread-local state is no longer recommended</a>). </p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><p>Install with:</p><pre><code class="language-julia-repl hljs">julia&gt; import Pkg; Pkg.add(&quot;ChunkSplitters&quot;)</code></pre><h2 id="The-chunks-iterator"><a class="docs-heading-anchor" href="#The-chunks-iterator">The <code>chunks</code> iterator</a><a id="The-chunks-iterator-1"></a><a class="docs-heading-anchor-permalink" href="#The-chunks-iterator" title="Permalink"></a></h2><p>The main interface is the <code>chunks</code> iterator:</p><pre><code class="language-julia hljs">chunks(array::AbstractArray, nchunks::Int, type::Symbol=:batch)</code></pre><p>This iterator returns a <code>Tuple{UnitRange,Int}</code> which indicates the range of indices of the input <code>array</code> for each given chunk and the index of the latter. The <code>type</code> parameter is optional. If <code>type == :batch</code>, the ranges are consecutive (default behavior). If <code>type == :scatter</code>, the range is scattered over the array.</p><p>The different chunking variants are illustrated in the following figure: </p><p><img src="assets/splitters.svg" alt="splitter types"/></p><p>For <code>type=:batch</code>, each chunk is &quot;filled up&quot; with work items one after another such that all chunks hold approximately the same number of work items (as far as possible). For <code>type=:scatter</code>, the work items are assigned to chunks in a round-robin fashion. As shown below, this way of chunking can be beneficial if the workload (i.e. the computational weight) for different items is uneven. </p><h2 id="Basic-example"><a class="docs-heading-anchor" href="#Basic-example">Basic example</a><a id="Basic-example-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-example" title="Permalink"></a></h2><p>Let&#39;s first illustrate the chunks returned by <code>chunks</code> for the different chunking variants:</p><pre><code class="language-julia hljs">julia&gt; using ChunkSplitters 

julia&gt; x = rand(7);

julia&gt; for (xrange,ichunk) in chunks(x, 3, :batch)
           @show (xrange, ichunk)
       end
(xrange, ichunk) = (1:3, 1)
(xrange, ichunk) = (4:5, 2)
(xrange, ichunk) = (6:7, 3)

julia&gt; for (xrange,ichunk) in chunks(x, 3, :scatter)
           @show (xrange, ichunk)
       end
(xrange, ichunk) = (1:3:7, 1)
(xrange, ichunk) = (2:3:5, 2)
(xrange, ichunk) = (3:3:6, 3)</code></pre><p>Now, let&#39;s demonstrate how to use chunks in a simple multi-threaded example:</p><pre><code class="language-julia hljs">julia&gt; using BenchmarkTools

julia&gt; using ChunkSplitters

julia&gt; function sum_parallel(f, x; nchunks=Threads.nthreads())
           t = map(chunks(x, nchunks)) do (idcs, ichunk)
               Threads.@spawn sum(f, @view x[idcs])
           end
           return sum(fetch.(t))
       end

julia&gt; x = rand(10^8);

julia&gt; Threads.nthreads()
12

julia&gt; @btime sum(x -&gt; log(x)^7, $x);
  1.353 s (0 allocations: 0 bytes)

julia&gt; @btime sum_parallel(x -&gt; log(x)^7, $x; nchunks=Threads.nthreads());
  120.429 ms (98 allocations: 7.42 KiB)</code></pre><p>Of course, <code>chunks</code> can also be used in conjuction with <code>@threads</code> (see below).</p><h2 id="Load-balancing-considerations"><a class="docs-heading-anchor" href="#Load-balancing-considerations">Load balancing considerations</a><a id="Load-balancing-considerations-1"></a><a class="docs-heading-anchor-permalink" href="#Load-balancing-considerations" title="Permalink"></a></h2><p>We create a very unbalanced workload:</p><pre><code class="language-julia-repl hljs">julia&gt; work_load = ceil.(Int, collect(10^3 * exp(-0.002*i) for i in 1:2^11));

julia&gt; using UnicodePlots

julia&gt; lineplot(work_load; xlabel=&quot;task&quot;, ylabel=&quot;workload&quot;, xlim=(1,2^11))
                  ┌────────────────────────────────────────┐ 
            1 000 │⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                  │⠘⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                  │⠀⢹⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                  │⠀⠀⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                  │⠀⠀⠀⢧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                  │⠀⠀⠀⠈⢧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                  │⠀⠀⠀⠀⠈⢳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
   workload       │⠀⠀⠀⠀⠀⠀⠳⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                  │⠀⠀⠀⠀⠀⠀⠀⠙⢦⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                  │⠀⠀⠀⠀⠀⠀⠀⠀⠈⠳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⢦⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠲⢤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠓⠦⠤⣄⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│ 
                0 │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠉⠓⠒⠒⠒⠦⠤⠤⠤⠤⠤⠤│ 
                  └────────────────────────────────────────┘ 
                  ⠀1⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀2 048⠀ 
                  ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀task⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ </code></pre><p>The scenario that we will consider below is the following: We want to parallize the operation <code>sum(y -&gt; log(y)^7, x)</code>, where <code>x</code> is a regular array. However, to establish the uneven workload shown above, we will make each task sum up a different number of elements of <code>x</code>, specifically as many elements as is indicated by the <code>work_load</code> array for the given task/work item.</p><p>For parallelization, we will use <code>@spawn</code> and <code>@threads</code>, which, respectively, does and doesn&#39;t implement load balancing. We&#39;ll test those in conjuction with the chunking variants <code>:batch</code> and <code>:scatter</code> described above.</p><h3 id="Using-@threads"><a class="docs-heading-anchor" href="#Using-@threads">Using <code>@threads</code></a><a id="Using-@threads-1"></a><a class="docs-heading-anchor-permalink" href="#Using-@threads" title="Permalink"></a></h3><p>First, we consider a variant where the <code>@threads</code> macro is used. The multithreaded operation is:</p><pre><code class="language-julia hljs">julia&gt; using Base.Threads, ChunkSplitters

julia&gt; function uneven_workload_threads(x, work_load; nchunks::Int, chunk_type::Symbol)
           chunk_sums = Vector{eltype(x)}(undef, nchunks)
           @threads for (idcs, ichunk) in chunks(work_load, nchunks, chunk_type)
               local s = zero(eltype(x))
               for i in idcs
                   s += sum(j -&gt; log(x[j])^7, 1:work_load[i])
               end
               chunk_sums[ichunk] = s
           end
           return sum(chunk_sums)
       end</code></pre><p>Using <code>nchunks == Thread.nthreads() == 12</code>, we get the following timings:</p><pre><code class="language-julia hljs">julia&gt; using BenchmarkTools 

julia&gt; @btime uneven_workload_threads($x, $work_load; nchunks=nthreads(), chunk_type=:batch)
  2.030 ms (71 allocations: 7.06 KiB)

julia&gt; @btime uneven_workload_threads($x, $work_load; nchunks=nthreads(), chunk_type=:scatter)
  587.309 μs (70 allocations: 7.03 KiB)</code></pre><p>Note that despite the fact that <code>@threads</code> doesn&#39;t balance load internally, one can get &quot;poor man&#39;s load balancing&quot; by using <code>:scatter</code> instead of <code>:batch</code>. This is due to the fact that for <code>:scatter</code> we create chunks by <em>sampling</em> from the entire workload: chunks will consist of work items with vastly different computational weight. In contrast, for <code>:batch</code>, the first couple of chunks will have high workload and the latter ones very low workload.</p><p>For <code>@threads</code>, increasing <code>nchunks</code> beyond <code>nthreads()</code> typically isn&#39;t helpful. This is because it will anyways always create O(<code>nthreads()</code>) tasks (i.e. a fixed number), grouping up multiple of our chunks if necessary.</p><pre><code class="language-julia hljs">julia&gt; @btime uneven_workload_threads($x, $work_load; nchunks=8*nthreads(), chunk_type=:batch);
  2.081 ms (74 allocations: 7.88 KiB)

julia&gt; @btime uneven_workload_threads($x, $work_load; nchunks=8*nthreads(), chunk_type=:scatter);
  632.149 μs (75 allocations: 7.91 KiB)</code></pre><h3 id="Using-@spawn"><a class="docs-heading-anchor" href="#Using-@spawn">Using <code>@spawn</code></a><a id="Using-@spawn-1"></a><a class="docs-heading-anchor-permalink" href="#Using-@spawn" title="Permalink"></a></h3><p>We can use <code>@spawn</code> to get &quot;proper&quot; load balancing through Julia&#39;s task scheduler. The spawned tasks, each associated with a chunk of the <code>work_load</code> array, will be dynamically scheduled at runtime. If there are enough tasks/chunks, the scheduler can map them to Julia threads in such a way that the overall workload per Julia thread is balanced.</p><p>Here is the implementation that we&#39;ll consider.</p><pre><code class="language-julia hljs">julia&gt; function uneven_workload_spawn(x, work_load; nchunks::Int, chunk_type::Symbol)
           ts = map(chunks(work_load, nchunks, chunk_type)) do (idcs, ichunk)
               @spawn begin
                   local s = zero(eltype(x))
                   for i in idcs
                       s += sum(log(x[j])^7 for j in 1:work_load[i])
                   end
                   s
               end
           end
           return sum(fetch.(ts))
       end</code></pre><p>For <code>nchunks == Thread.nthreads() == 12</code>, we expect to see similar performance as for the <code>@threads</code> variant above, because we&#39;re creating the same (number of) chunks/tasks.</p><pre><code class="language-julia hljs">julia&gt; @btime uneven_workload_spawn($x, $work_load; nchunks=nthreads(), chunk_type=:batch);
  1.997 ms (93 allocations: 7.30 KiB)

julia&gt; @btime uneven_workload_spawn($x, $work_load; nchunks=nthreads(), chunk_type=:scatter);
  573.399 μs (91 allocations: 7.23 KiB)</code></pre><p>However, by increasing <code>nchunks &gt; nthreads()</code> we can give the dynamic scheduler more tasks (&quot;units of work&quot;) to balance out and improve the load balancing. In this case, the difference between <code>:batch</code> and <code>:scatter</code> chunking becomes negligible.</p><pre><code class="language-julia hljs">julia&gt; @btime uneven_workload_spawn($x, $work_load; nchunks=8*nthreads(), chunk_type=:batch);
  603.830 μs (597 allocations: 53.30 KiB)

julia&gt; @btime uneven_workload_spawn($x, $work_load; nchunks=8*nthreads(), chunk_type=:scatter);
  601.519 μs (597 allocations: 53.30 KiB)</code></pre><h2 id="Lower-level-getchunk-function"><a class="docs-heading-anchor" href="#Lower-level-getchunk-function">Lower-level <code>getchunk</code> function</a><a id="Lower-level-getchunk-function-1"></a><a class="docs-heading-anchor-permalink" href="#Lower-level-getchunk-function" title="Permalink"></a></h2><p>The package also provides a lower-level <code>getchunk</code> function:</p><pre><code class="language-julia hljs">getchunk(array::AbstractArray, ichunk::Int, nchunks::Int, type::Symbol=:batch)</code></pre><p>that returns the range of indexes corresponding to the work items in the input <code>array</code> that are associated with chunk number <code>ichunk</code>. </p><p>For example, if we have an array of 7 elements, and the work on the elements is divided into 3 chunks, we have (using the default <code>type = :batch</code> option):</p><pre><code class="language-julia hljs">julia&gt; using ChunkSplitters

julia&gt; x = rand(7);

julia&gt; getchunk(x, 1, 3)
1:3

julia&gt; getchunk(x, 2, 3)
4:5

julia&gt; getchunk(x, 3, 3)
6:7</code></pre><p>And using <code>type = :scatter</code>, we have:</p><pre><code class="language-julia hljs">julia&gt; getchunk(x, 1, 3, :scatter)
1:3:7

julia&gt; getchunk(x, 2, 3, :scatter)
2:3:5

julia&gt; getchunk(x, 3, 3, :scatter)
3:3:6</code></pre><h3 id="Example:-getchunk-usage"><a class="docs-heading-anchor" href="#Example:-getchunk-usage">Example: <code>getchunk</code> usage</a><a id="Example:-getchunk-usage-1"></a><a class="docs-heading-anchor-permalink" href="#Example:-getchunk-usage" title="Permalink"></a></h3><pre><code class="language-julia hljs">julia&gt; using BenchmarkTools

julia&gt; using ChunkSplitters

julia&gt; function sum_parallel_getchunk(f, x; nchunks=Threads.nthreads())
           t = map(1:nchunks) do ichunk
               Threads.@spawn begin
                   local idcs = getchunk(x, ichunk, nchunks)
                   sum(f, @view x[idcs])
               end
           end
           return sum(fetch.(t))
       end

julia&gt; x = rand(10^8);

julia&gt; Threads.nthreads()
12

julia&gt; @btime sum(x -&gt; log(x)^7, $x);
  1.363 s (0 allocations: 0 bytes)

julia&gt; @btime sum_parallel_getchunk(x -&gt; log(x)^7, $x; nchunks=Threads.nthreads());
  121.651 ms (100 allocations: 7.31 KiB)</code></pre></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="references/">References »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.2 on <span class="colophon-date" title="Monday 13 November 2023 13:39">Monday 13 November 2023</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
